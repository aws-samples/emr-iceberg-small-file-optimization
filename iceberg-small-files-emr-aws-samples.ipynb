{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150fcad-5f3d-45d1-91e5-82a1852abb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32d4ebd7-0ffe-46b0-a912-64f4c79776d5",
   "metadata": {},
   "source": [
    "**Iceberg AWS Event Based Table Management for EMR-6.11 Spark Cluster**\n",
    "\n",
    "**Step1.** Configuring Iceberg on Spark session\n",
    "\n",
    "Configure your Spark session using the %%configure magic command. We will be using Hive Catalog for Iceberg Tables. Before you run the following step, create a S3 bucket in your AWS account with following naming convemtion /iceberg/\n",
    "\n",
    "Update the your-iceberg-storage-blog in below configuration with the bucket which you created to test this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75d4365-e2df-46bb-be27-49f16e3901c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T15:15:03.454605Z",
     "iopub.status.busy": "2023-07-26T15:15:03.454280Z",
     "iopub.status.idle": "2023-07-26T15:15:04.003434Z",
     "shell.execute_reply": "2023-07-26T15:15:04.002548Z",
     "shell.execute_reply.started": "2023-07-26T15:15:03.454573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.extensions': 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', 'spark.sql.catalog.dev': 'org.apache.iceberg.spark.SparkCatalog', 'spark.sql.catalog.dev.catalog-impl': 'org.apache.iceberg.aws.glue.GlueCatalog', 'spark.sql.catalog.dev.io-impl': 'org.apache.iceberg.aws.s3.S3FileIO', 'spark.sql.catalog.dev.warehouse': 's3://iceberg-file-optimization/iceberg/'}, 'proxyUser': 'user_Administrator', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"conf\":{\n",
    "    \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.catalog.dev\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.dev.catalog-impl\":\"org.apache.iceberg.aws.glue.GlueCatalog\",\n",
    "    \"spark.sql.catalog.dev.io-impl\":\"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.catalog.dev.warehouse\":\"s3://<your-iceberg-storage-blog>/iceberg/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e02e27-8b66-4542-9140-dd52181c6497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T16:50:19.925066Z",
     "iopub.status.busy": "2023-07-26T16:50:19.924768Z",
     "iopub.status.idle": "2023-07-26T16:50:33.254584Z",
     "shell.execute_reply": "2023-07-26T16:50:33.253990Z",
     "shell.execute_reply.started": "2023-07-26T16:50:19.925039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98552356d5154ee09dfb6075ef48e634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" DROP TABLE  iceberg_db.sensor_data_parquet_table \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f156f-3dce-4971-bd6e-577b5176f99b",
   "metadata": {},
   "source": [
    "**Step2.** Create a new database for the Iceberg table in the AWS Glue Data Catalog named DB and provide the S3 URI specified in the Spark config as s3://<your-iceberg-storage-blog>/iceberg/db. Also, create another Database named iceberg_db in Glue for the parquet tables.\"\n",
    "\n",
    "\n",
    "Create a new Spark table in Parquet format pointing to the bucket containing small object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3869c9fc-8e8f-420e-bd42-2dc3ca40b8ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T16:50:35.920260Z",
     "iopub.status.busy": "2023-07-26T16:50:35.919962Z",
     "iopub.status.idle": "2023-07-26T16:50:45.228921Z",
     "shell.execute_reply": "2023-07-26T16:50:45.228062Z",
     "shell.execute_reply.started": "2023-07-26T16:50:35.920235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882b578e96c943cb93002215f9912b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE TABLE  iceberg_db.sensor_data_parquet_table (\n",
    "    sensorid int, \n",
    "    currenttemperature int, \n",
    "    status string, \n",
    "    date_ts timestamp)\n",
    "USING parquet \n",
    "location 's3://<your-iceberg-storage-blog>/sensor_data_smallfiles_parquet/'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc96a3a-fbdb-4d46-9198-af4e97708309",
   "metadata": {},
   "source": [
    "**Step3.** Now let's run a aggregate SQL to measure the performance of Spark SQL on the parquet table with 58,176 small object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e205f48-7fd2-47a8-8aa6-1d73228fd3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T16:50:49.128647Z",
     "iopub.status.busy": "2023-07-26T16:50:49.128349Z",
     "iopub.status.idle": "2023-07-26T16:59:36.251486Z",
     "shell.execute_reply": "2023-07-26T16:59:36.250886Z",
     "shell.execute_reply.started": "2023-07-26T16:50:49.128622Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7de374500da4eedb26d190e6f58eec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+\n",
      "|maxtemp|mintemp|          avgtemp|\n",
      "+-------+-------+-----------------+\n",
      "|    150|     10|79.99732039114782|\n",
      "+-------+-------+-----------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select maxtemp, mintemp, avgtemp from \n",
    "(select\n",
    " max(currenttemperature) as maxtemp, \n",
    " min(currenttemperature) as mintemp, \n",
    " avg(currenttemperature) as avgtemp \n",
    " from iceberg_db.sensor_data_parquet_table\n",
    " where month(date_ts) between 2 and 10\n",
    " order by  maxtemp, mintemp, avgtemp)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e4fc2-1432-4350-a01f-4af8d1ba28d0",
   "metadata": {},
   "source": [
    "**Result:** The execution time noted for the above aggregation query as **8m 47.12s**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3613b71-3a25-4e8c-8b2b-a1eae2b60904",
   "metadata": {},
   "source": [
    "**>>Now in the following steps we will create a new Iceberg table from the Spark/Parquet table using CTAS. After this step, we will show how the automated compaction job is going to help improve the performance of the queries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35178dbf-b6fe-4ad0-aab5-ca8a6fdb2435",
   "metadata": {},
   "source": [
    "**Step4.** Let's create a new Iceberg table using CTAS (Create Table As Select) from the earlier Spark/Glue table having the small files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27fb5070-96bc-4aaf-9441-0663120259a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:00:25.594265Z",
     "iopub.status.busy": "2023-07-26T17:00:25.593939Z",
     "iopub.status.idle": "2023-07-26T17:00:27.853382Z",
     "shell.execute_reply": "2023-07-26T17:00:27.852757Z",
     "shell.execute_reply.started": "2023-07-26T17:00:25.594237Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aec80fb26c74bc1bf8470a312a535e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" DROP TABLE IF EXISTS dev.db.sensor_data_iceberg_format \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93843ad2-62bf-46da-a44b-fca46ccdaeb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:00:49.928984Z",
     "iopub.status.busy": "2023-07-26T17:00:49.928660Z",
     "iopub.status.idle": "2023-07-26T17:08:50.633168Z",
     "shell.execute_reply": "2023-07-26T17:08:50.632547Z",
     "shell.execute_reply.started": "2023-07-26T17:00:49.928956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa38a88150584c8e93b72395283f1c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" CREATE TABLE dev.db.sensor_data_iceberg_format USING iceberg AS (SELECT * FROM iceberg_db.sensor_data_parquet_table)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775bcb5c-c7d5-4e11-b2f1-ea9b5b507c67",
   "metadata": {},
   "source": [
    "**Step5.** Validate a new Iceberg snapshot created for the new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34985c01-371a-4e05-94cd-eadb1c384512",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:11:37.284152Z",
     "iopub.status.busy": "2023-07-26T17:11:37.283839Z",
     "iopub.status.idle": "2023-07-26T17:11:38.033618Z",
     "shell.execute_reply": "2023-07-26T17:11:38.032924Z",
     "shell.execute_reply.started": "2023-07-26T17:11:37.284126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9263b52eaf4d2aa16e2fdac2c71542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+\n",
      "|2023-07-26 17:08:...|5276645498530515109|     null|   append|s3://iceberg-file...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+---------+---------+--------------------+--------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select * from dev.db.sensor_data_iceberg_format.snapshots limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcaa25c-3ced-450e-b609-841fb078b57e",
   "metadata": {},
   "source": [
    "**Validation:** Validate the S3 Data folder corresponding to the newly created Iceberg table. It shows that during the CTAS statement above it added 1,879 objects in the new /Data folder with total size of 1.3GB. So Iceberg did some optimization while loading data from parquet table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83c1ab-9ad0-44ca-a771-114c7b756fd7",
   "metadata": {},
   "source": [
    "**Step6:** Now we have data in the Iceberg table, let's run the previous Aggregation SQL to check the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f63961-801e-41c3-88cf-3fc72c3c4e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:09:29.885774Z",
     "iopub.status.busy": "2023-07-26T17:09:29.885452Z",
     "iopub.status.idle": "2023-07-26T17:11:09.444451Z",
     "shell.execute_reply": "2023-07-26T17:11:09.443501Z",
     "shell.execute_reply.started": "2023-07-26T17:09:29.885748Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843f2439757d430faeaf49139b3c25c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+\n",
      "|maxtemp|mintemp|          avgtemp|\n",
      "+-------+-------+-----------------+\n",
      "|    150|     10|79.99732039114782|\n",
      "+-------+-------+-----------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select maxtemp, mintemp, avgtemp from \n",
    "(select\n",
    " max(currenttemperature) as maxtemp, \n",
    " min(currenttemperature) as mintemp, \n",
    " avg(currenttemperature) as avgtemp \n",
    " from dev.db.sensor_data_iceberg_format\n",
    " where month(date_ts) between 2 and 10\n",
    " order by  maxtemp, mintemp, avgtemp)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130b968-e562-4660-825c-0d1967f781a7",
   "metadata": {},
   "source": [
    "**Result** Note the execution time for the above aggregation query ran on the Iceberg table with 1879 objects as **1m 39.56s**. There is already some significant performance improvement by converting the expternal parquet table to Iceberg table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240d7ac-8254-4bdf-9891-b907c69ca4b6",
   "metadata": {},
   "source": [
    "**Step7.** Now let's add the configurations we will need to apply the automatic compaction of small files of Iceberg tables. Note the last four newly added configurations in the following statement. Parameter \"optimize-data.commit-threshold\" suggests that the compaction will take place after the the 1st successful commit. The dafault is 10 successful commit to trigger the compaction. For this testing we are using just 1 commit to trigger the compaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1513ff16-3b03-43d3-b860-3e29dae5f22e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:19:01.941881Z",
     "iopub.status.busy": "2023-07-26T17:19:01.941558Z",
     "iopub.status.idle": "2023-07-26T17:19:51.060869Z",
     "shell.execute_reply": "2023-07-26T17:19:51.059991Z",
     "shell.execute_reply.started": "2023-07-26T17:19:01.941855Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n<tbody><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1690346859076_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-5-132.ec2.internal:20888/proxy/application_1690346859076_0002/\" class=\"emr-proxy-link j-1N8J5NZI0KEU3 application_1690346859076_0002\" emr-resource=\"j-1N8J5NZI0KEU3\n\" application-id=\"application_1690346859076_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-5-226.ec2.internal:8042/node/containerlogs/container_1690346859076_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.extensions': 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', 'spark.sql.catalog.dev': 'org.apache.iceberg.spark.SparkCatalog', 'spark.sql.catalog.dev.catalog-impl': 'org.apache.iceberg.aws.glue.GlueCatalog', 'spark.sql.catalog.dev.io-impl': 'org.apache.iceberg.aws.s3.S3FileIO', 'spark.sql.catalog.dev.warehouse': 's3://iceberg-file-optimization/iceberg/', 'spark.sql.catalog.dev.metrics-reporter-impl': 'org.apache.iceberg.aws.manage.AwsTableManagementMetricsEvaluator', 'spark.sql.catalog.dev.optimize-data.impl': 'org.apache.iceberg.aws.manage.EmrOnEc2OptimizeDataExecutor', 'spark.sql.catalog.dev.optimize-data.emr.cluster-id': 'j-1N8J5NZI0KEU3', 'spark.sql.catalog.dev.optimize-data.commit-threshold': '1'}, 'proxyUser': 'user_Administrator', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n<tbody><tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1690346859076_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-5-132.ec2.internal:20888/proxy/application_1690346859076_0002/\" class=\"emr-proxy-link j-1N8J5NZI0KEU3 application_1690346859076_0002\" emr-resource=\"j-1N8J5NZI0KEU3\n\" application-id=\"application_1690346859076_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-5-226.ec2.internal:8042/node/containerlogs/container_1690346859076_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "\"conf\":{\n",
    "    \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.catalog.dev\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.dev.catalog-impl\":\"org.apache.iceberg.aws.glue.GlueCatalog\",\n",
    "    \"spark.sql.catalog.dev.io-impl\":\"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.catalog.dev.warehouse\":\"s3://<your-iceberg-storage-blog>/iceberg/\",\n",
    "    \"spark.sql.catalog.dev.metrics-reporter-impl\":\"org.apache.iceberg.aws.manage.AwsTableManagementMetricsEvaluator\",\n",
    "    \"spark.sql.catalog.dev.optimize-data.impl\":\"org.apache.iceberg.aws.manage.EmrOnEc2OptimizeDataExecutor\",\n",
    "    \"spark.sql.catalog.dev.optimize-data.emr.cluster-id\":\"j-xxxxxxxxxxxx\",\n",
    "    \"spark.sql.catalog.dev.optimize-data.commit-threshold\":\"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82e696-67d0-4c28-812f-6f77f84f436d",
   "metadata": {},
   "source": [
    "**Step8.** A Quick sanity check that the configurations are working fine with Spark-SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65e2a759-8b6a-4754-8cf8-7ec131b64fa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:20:04.104342Z",
     "iopub.status.busy": "2023-07-26T17:20:04.104012Z",
     "iopub.status.idle": "2023-07-26T17:20:19.426787Z",
     "shell.execute_reply": "2023-07-26T17:20:19.426185Z",
     "shell.execute_reply.started": "2023-07-26T17:20:04.104315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7debfe509b34a31bf3d8f88a12c7425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------+-------------------+\n",
      "|sensorid|currenttemperature|status|            date_ts|\n",
      "+--------+------------------+------+-------------------+\n",
      "|    2811|               116|  FAIL|2023-06-07 14:50:25|\n",
      "+--------+------------------+------+-------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select * from dev.db.sensor_data_iceberg_format limit 1 \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea002f32-cb79-43bc-a14b-151a96ed34d0",
   "metadata": {},
   "source": [
    "**Step9.** Now to activate the automatic compaction process, we have to add a new record to the existing Iceberg table. Let's add a new record in the table using Spark Insert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80477cf5-617a-4ef8-a696-ced83b0faa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:21:34.971587Z",
     "iopub.status.busy": "2023-07-26T17:21:34.971265Z",
     "iopub.status.idle": "2023-07-26T17:21:46.272943Z",
     "shell.execute_reply": "2023-07-26T17:21:46.272325Z",
     "shell.execute_reply.started": "2023-07-26T17:21:34.971559Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7fc4b8a5a048d6801378b95e2adc36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Insert into dev.db.sensor_data_iceberg_format values(999123, 86, 'PASS', timestamp'2023-07-26 12:50:25') \"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3dfc8-d99a-4384-8265-a09d1b418412",
   "metadata": {},
   "source": [
    "**Step10.** Go to EMR Console to check the Cluster Steps. You should see a new Step added which goes from Pending to Running and finally Completed state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de333cec-2b05-4b15-be2f-216be5889810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:32:04.471255Z",
     "iopub.status.busy": "2023-07-26T17:32:04.470951Z",
     "iopub.status.idle": "2023-07-26T17:32:04.571821Z",
     "shell.execute_reply": "2023-07-26T17:32:04.570953Z",
     "shell.execute_reply.started": "2023-07-26T17:32:04.471229Z"
    }
   },
   "source": [
    "**Step11:** Validate that the record inserted was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80c56d33-c53a-4cf2-ade1-3e57acc2ca21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T04:13:23.950491Z",
     "iopub.status.busy": "2023-07-26T04:13:23.950030Z",
     "iopub.status.idle": "2023-07-26T04:13:35.255688Z",
     "shell.execute_reply": "2023-07-26T04:13:35.254908Z",
     "shell.execute_reply.started": "2023-07-26T04:13:23.950449Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f97ebb825044d7c8cee3f989bab786d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------+-------------------+\n",
      "|sensorid|currenttemperature|status|            date_ts|\n",
      "+--------+------------------+------+-------------------+\n",
      "|  999999|                92|  FAIL|2023-07-26 01:50:25|\n",
      "+--------+------------------+------+-------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select * from dev.db.sensor_data_iceberg_format where sensorid = 999123 and date_ts = timestamp'2023-07-26 12:50:25' \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e937b08-609e-4ae5-945f-2cd9a9999972",
   "metadata": {},
   "source": [
    "**Step12:** Check the snapshot table to see that a new snapshot is created for the table with operation as **replace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba52e1e-6eb6-4b64-9784-5770e5c423a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:33:29.458637Z",
     "iopub.status.busy": "2023-07-26T17:33:29.458339Z",
     "iopub.status.idle": "2023-07-26T17:33:36.738180Z",
     "shell.execute_reply": "2023-07-26T17:33:36.737565Z",
     "shell.execute_reply.started": "2023-07-26T17:33:29.458612Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf83cdc935f4923b1bcce2e11e1ec80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|2023-07-26 17:08:...|5276645498530515109|               null|   append|s3://iceberg-file...|{spark.app.id -> ...|\n",
      "|2023-07-26 17:21:...|3706857927051738345|5276645498530515109|   append|s3://iceberg-file...|{spark.app.id -> ...|\n",
      "|2023-07-26 17:28:...|  27167933715576041|3706857927051738345|  replace|s3://iceberg-file...|{added-data-files...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" Select * from dev.db.sensor_data_iceberg_format.snapshots limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcd85c-b770-487a-9dbd-b3a50f3850db",
   "metadata": {},
   "source": [
    "**Step13.** Go to the S3 bucket /Data folder corresponding to the Iceberg table and see that the data files are compacted from the previous smaller sizes to ~437MB. The /Data folder will still contain the previous smaller files for time-travel perspective unless you issue an expiere snapshot to remove them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1589d0a6-41d4-48bf-8cd1-177541d0c099",
   "metadata": {},
   "source": [
    "**Step14.** Now let's run the same aggregate query and record the performance after the compaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae43de95-cf76-4a60-9e7a-6550137d3101",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T17:37:20.863183Z",
     "iopub.status.busy": "2023-07-26T17:37:20.862871Z",
     "iopub.status.idle": "2023-07-26T17:38:20.293513Z",
     "shell.execute_reply": "2023-07-26T17:38:20.292837Z",
     "shell.execute_reply.started": "2023-07-26T17:37:20.863156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecd9838ab4144f3bd8225e0ccb3a655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------------+\n",
      "|maxtemp|mintemp|          avgtemp|\n",
      "+-------+-------+-----------------+\n",
      "|    150|     10|79.99732040101847|\n",
      "+-------+-------+-----------------+"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\" select maxtemp, mintemp, avgtemp from \n",
    "(select\n",
    " max(currenttemperature) as maxtemp, \n",
    " min(currenttemperature) as mintemp, \n",
    " avg(currenttemperature) as avgtemp \n",
    " from dev.db.sensor_data_iceberg_format\n",
    " where month(date_ts) between 2 and 10\n",
    " order by  maxtemp, mintemp, avgtemp)\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d13e9-9274-41bf-b514-5b801c850808",
   "metadata": {},
   "source": [
    "**Summary of EMR Testing:** Note the execution time for the above aggregation query ran on the compacted Iceberg table reduced to **59.43s** from the previous run time of **1m 39.56s**. That is about **40%** improvement. With more small files you have in our source bucket, you would realize more performance boost with this post-hook compaction implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
